{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":11776,"status":"ok","timestamp":1713148849330,"user":{"displayName":"弘中誠勝","userId":"13242022006944237501"},"user_tz":-540},"id":"NEQ4y27FWUGL"},"outputs":[],"source":["import os\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import LinearSegmentedColormap\n","from PIL import Image\n","import base64\n","from IPython import display as dd\n","\n","import norse.torch.functional.stdp as stdp\n","from norse.torch import PoissonEncoder\n","from norse.torch import LIFParameters, LIFFeedForwardState\n","from norse.torch.module.lif import LIFCell\n","from norse.torch.functional.stdp import STDPState, STDPParameters"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1713149090693,"user":{"displayName":"弘中誠勝","userId":"13242022006944237501"},"user_tz":-540},"id":"QqncDovMWiJ2"},"outputs":[],"source":["transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","\n","train_data = torchvision.datasets.MNIST(\n","    root=\"./data\",\n","    train=True,\n","    download=True,\n","    transform=transform,\n",")\n","\n","test_data = torchvision.datasets.MNIST(\n","    root=\"./data\",\n","    train=False,\n","    download=True,\n","    transform=transform,\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def get_k_winnners_(z: torch.Tensor, k: int):\n","    \"\"\"\n","    スパイク活性を制限するために、入力テンソルの各サンプルについて、\n","    k個以上のスパイクがある場合にランダムにk個を選択し、それ以外のスパイクを0に変更します。\n","\n","    Args:\n","        z (torch.Tensor): ニューロンの出力スパイク活性を表すテンソル。\n","        k (int): 選択するスパイクの最大数。\n","\n","    Returns:\n","        None: 元のテンソルを変更し、返り値はありません。\n","    \"\"\"\n","    for i in range(z.size(0)):\n","        indices_of_ones = torch.nonzero(z[i]).squeeze(1)\n","        if len(indices_of_ones) > k:\n","            random_index = torch.randint(indices_of_ones.size(0), (k,))\n","            z[i] = torch.zeros_like(z[i])\n","            for j in random_index:\n","                z[i][indices_of_ones[j]] = 1.0\n","    return\n","\n","\n","def win_take_all_(state: LIFFeedForwardState, z: torch.Tensor, w: torch.Tensor):\n","    \"\"\"\n","    Win-Take-Allアルゴリズムに基づいて、ニューロンの入力電流を更新します。\n","\n","    Args:\n","        state (LIFFeedForwardState): LIFニューロンの状態を表すオブジェクト。\n","        z (torch.Tensor): ニューロンの出力スパイク活性を表すテンソル。\n","        w (torch.Tensor): 側方抑制の重みを表すテンソル。\n","\n","    Returns:\n","        None: 元の状態オブジェクトを変更し、返り値はありません。\n","    \"\"\"\n","    state.i.data = state.i + w * (z - torch.sum(z, dim=1, keepdim=True))\n","    return"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class MNIST(nn.Module):\n","    def __init__(self, input_neurons: int, excitatory_neurons: int):\n","        super(MNIST, self).__init__()\n","        self.input_neurons = input_neurons\n","        self.excitatory_neurons = excitatory_neurons\n","\n","        # 入力層から興奮層への全結合(weight: 0~1)\n","        self.liner_inp_exc = nn.Linear(input_neurons, excitatory_neurons, bias=False)\n","        nn.init.normal_(self.liner_inp_exc.weight, mean=0.3, std=0.05)\n","        # 興奮層のニューロン\n","        self.lifcell_exc = LIFCell(\n","            p=LIFParameters(tau_mem_inv=torch.as_tensor(1.0 / 50e-3))\n","        )\n","        # STDP用のパラメータ\n","        self.stdp_parameter = STDPParameters(\n","            eta_plus=torch.as_tensor(1e-3),\n","            eta_minus=torch.as_tensor(1e-4),\n","            stdp_algorithm=\"additive_step\",\n","            hardbound=False,\n","        )\n","\n","    def forward(self, x: torch.Tensor, train: bool):\n","        time, batch_size, _, _, _ = x.shape\n","        state_exc = None\n","\n","        with torch.no_grad():\n","            if train:\n","                state_stdp = STDPState(\n","                    t_pre=torch.zeros(self.input_neurons, device=x.device),\n","                    t_post=torch.zeros(self.excitatory_neurons, device=x.device),\n","                )\n","                for t in range(time):\n","                    z_pre = x[t, :, :, :].view(-1, self.input_neurons)\n","                    z = self.liner_inp_exc(z_pre)\n","                    z_post, state_exc = self.lifcell_exc(z, state_exc)\n","                    # get_k_winnners_(z=z_post, k=1)\n","                    win_take_all_(state=state_exc, z=z_post, w=torch.tensor(40.0))\n","\n","                    w, state_stdp = stdp.stdp_step_linear(\n","                        z_pre=z_pre,\n","                        z_post=z_post,\n","                        w=self.liner_inp_exc.weight,\n","                        state_stdp=state_stdp,\n","                        p_stdp=self.stdp_parameter,\n","                    )\n","                    w = w / torch.max(w, dim=1, keepdim=True)[0]\n","                    self.liner_inp_exc.weight.data = w\n","                return w\n","\n","            else:\n","                firing_rate = torch.zeros(\n","                    batch_size, self.excitatory_neurons, device=x.device\n","                )\n","                for t in range(time):\n","                    z = x[t, :, :, :].view(-1, self.input_neurons)\n","                    z = self.liner_inp_exc(z)\n","                    z, state_exc = self.lifcell_exc(z, state_exc)\n","                    firing_rate += z\n","                return firing_rate\n","\n","    def save(self, file_path: str = \"./mnist_model_parameters.pth\"):\n","        torch.save(self.state_dict(), file_path)\n","\n","    def load(self, file_path: str = \"./mnist_model_parameters.pth\"):\n","        self.load_state_dict(torch.load(file_path))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def visualize_tensor_as_grid(\n","    tensor: torch.Tensor,\n","    grid_rows: int,\n","    grid_cols: int,\n","    image_size: int = 28,\n","    save_path: str = None,\n","):\n","    \"\"\"\n","    テンソルを指定された行数と列数のグリッドに変換して保存する関数。\n","\n","    Args:\n","        tensor (torch.Tensor): 表示するテンソル\n","        grid_rows (int): グリッドの行数\n","        grid_cols (int): グリッドの列数\n","        image_size (int, optional): 画像のサイズ。デフォルトは28。\n","        save_path (str, optional): 画像を保存するパス。デフォルトはNone。\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    # 勾配を切り離してテンソルをnumpy配列に変換\n","    tensor = tensor.to(\"cpu\").detach().numpy()\n","\n","    # 画像を配置するキャンバスの初期化\n","    canvas = np.zeros((grid_rows * image_size, grid_cols * image_size))\n","\n","    # テンソルを画像に変換し、キャンバスに配置\n","    for i in range(grid_rows):\n","        for j in range(grid_cols):\n","            image = tensor[i * grid_cols + j].reshape(image_size, image_size)\n","            canvas[\n","                i * image_size : (i + 1) * image_size,\n","                j * image_size : (j + 1) * image_size,\n","            ] = image\n","\n","    # カスタムカラーマップの作成\n","    cmap = LinearSegmentedColormap.from_list(\n","        \"custom_cmap\", [(0, \"black\"), (1, \"green\")]\n","    )\n","\n","    # 画像を保存\n","    plt.figure(figsize=(5, 5))\n","    plt.imshow(canvas, cmap=cmap)\n","    plt.axis(\"off\")\n","    if save_path:\n","        plt.savefig(save_path, bbox_inches=\"tight\")\n","    plt.close()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["seed = 0\n","gpu = True\n","\n","# GPU使用の設定\n","if gpu and torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    torch.cuda.manual_seed_all(seed)\n","else:\n","    device = torch.device(\"cpu\")\n","    torch.manual_seed(seed)\n","    torch.set_num_threads(os.cpu_count() - 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# オンライン学習\n","BATCH_SIZE = 1\n","TIME = 300\n","interval = 10\n","train_loader = torch.utils.data.DataLoader(\n","    train_data, batch_size=BATCH_SIZE, shuffle=False\n",")\n","encoder = PoissonEncoder(TIME, f_max=64)\n","\n","model = MNIST(28 * 28, 10 * 10)\n","model.to(device)\n","\n","for i, (data, target) in enumerate(tqdm(train_loader, desc=\"Training\")):\n","    data = encoder(data).to(device)\n","    w = model(data, True)\n","    if i < 70000 and i % interval == 0:\n","        visualize_tensor_as_grid(\n","            w, 10, 10, save_path=f\"./weight/image_{int(i/interval)}.png\"\n","        )\n","    if i % 10000 == 0:\n","        model.save(\"./mnist_model_parameters.pth\")\n","\n","model.save(\"./mnist_model_parameters.pth\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (2770953460.py, line 2)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[11], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def__init__(self,n_labels:int,target:torch.Tensor,firing_rate:torch.Tensor,):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["class LabelAssignment:\n","    def __init__(\n","        self,\n","        n_labels: int,\n","        n_neurons: int,\n","        device: str,\n","    ):\n","        self.n_labels = n_labels\n","        self.n_neurons = n_neurons\n","        self.firing_rates = torch.zeros((n_neurons, n_labels), device=device)\n","        self.assignments = torch.zeros((n_neurons, n_labels), device=device)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 77.,  79.,  76.,  78.,  75.,  81.,  62.,  77.,  72.,  58.,  91.,  89.,\n","          53.,  74.,  80.,  63.,  70.,  72.,  87.,  74.,  59.,  73.,  94.,  68.,\n","          70.,  54.,  78.,  76.,  88.,  90.,  78.,  71.,  93., 105.,  67.,  77.,\n","          60.,  66.,  92.,  72.,  77.,  74.,  85.,  68.,  46.,  80.,  89.,  56.,\n","          59.,  54.,  74.,  75.,  61.,  98.,  99.,  74.,  98.,  74.,  61.,  73.,\n","          95.,  66.,  57.,  74.,  56., 100.,  75.,  82.,  90.,  84.,  58.,  78.,\n","          53.,  66.,  85.,  78.,  59.,  85.,  85.,  68.,  77.,  96.,  76.,  81.,\n","          89.,  75.,  68.,  61.,  73.,  68.,  99.,  93.,  74.,  68.,  70.,  92.,\n","          57.,  76.,  83.,  97.],\n","        [ 74., 118.,  81.,  70.,  70.,  93.,  70.,  71.,  77.,  53.,  69.,  79.,\n","          53.,  69.,  84.,  71.,  71.,  67.,  79.,  75.,  62.,  69., 142.,  66.,\n","          76.,  48.,  81.,  79.,  88.,  72.,  63.,  62.,  96., 103.,  84.,  74.,\n","          59.,  60.,  71.,  75.,  83.,  79.,  78.,  75.,  51., 124.,  85.,  55.,\n","          58.,  66.,  77.,  79.,  50.,  91., 100.,  81.,  92.,  70.,  72.,  75.,\n","          90.,  63.,  53.,  69.,  46., 102.,  74.,  70.,  90.,  77.,  59.,  74.,\n","          51.,  71., 106.,  82.,  53.,  69.,  78.,  68.,  70.,  90.,  68.,  95.,\n","          92.,  96.,  72.,  68.,  77.,  66.,  93., 116.,  79.,  78.,  58.,  93.,\n","          58.,  71.,  83.,  96.],\n","        [ 33.,  40.,  39.,  33.,  29.,  67.,  57.,  35.,  40.,  13.,  43.,  41.,\n","          26.,  28.,  31.,  69.,  39.,  37.,  40.,  36.,  23.,  35.,  44.,  32.,\n","          42.,  15.,  55.,  37.,  34.,  48.,  24.,  52.,  47.,  45.,  57.,  38.,\n","          23.,  14.,  40.,  33.,  40.,  44.,  29.,  39.,  18.,  42.,  43.,  16.,\n","          17.,  28.,  59.,  46.,  18.,  42.,  47.,  48.,  38.,  25.,  71.,  45.,\n","          39.,  66.,  14.,  39.,  11.,  39.,  37.,  47.,  45.,  40.,  17.,  32.,\n","          14.,  63.,  42.,  43.,  21.,  32.,  42.,  35.,  36.,  51.,  27.,  31.,\n","          36.,  39.,  44.,  49.,  52.,  51.,  39.,  53.,  37.,  48.,  47.,  36.,\n","          20.,  44.,  40.,  46.]])\n","tensor([5, 0, 4])\n"]}],"source":["# ラベル付け\n","BATCH_SIZE = 3\n","TIME = 300\n","train_loader = torch.utils.data.DataLoader(\n","    train_data, batch_size=BATCH_SIZE, shuffle=False\n",")\n","encoder = PoissonEncoder(TIME, f_max=64)\n","\n","\n","model = MNIST(28 * 28, 10 * 10)\n","model.load(\"./mnist_model_parameters.pth\")\n","model.to(device)\n","for i, (data, target) in enumerate(train_loader):\n","    data = encoder(data).to(device)\n","    firing_rate = model(data, False)\n","    print(firing_rate)\n","    print(target)\n","    if i == 0:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# テスト\n","BATCH_SIZE = 10\n","TIME = 300\n","test_loader = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=BATCH_SIZE,\n",")\n","encoder = PoissonEncoder(TIME, f_max=64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNGl0tE7C7a0TyAun1G0+it","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
